{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question-answering-bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f70c3487ec1044069b32219480a253d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cc62d1966464ddc80ab11b27f05fec6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d476d3c168db4df9a9af22b47adcef51",
              "IPY_MODEL_fd84b542a6644d78be436c8edb17c848"
            ]
          }
        },
        "7cc62d1966464ddc80ab11b27f05fec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d476d3c168db4df9a9af22b47adcef51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a8e282c9fe3495b8e78fb82b6cf7ebf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae4e315f5b634dcf9e3f0a5b62151155"
          }
        },
        "fd84b542a6644d78be436c8edb17c848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa2f65437a194feab00a2e62defc9dbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e17bdc16fb94f698e715a471b2c95a2"
          }
        },
        "6a8e282c9fe3495b8e78fb82b6cf7ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae4e315f5b634dcf9e3f0a5b62151155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa2f65437a194feab00a2e62defc9dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e17bdc16fb94f698e715a471b2c95a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cbcd2d188974b96bd9af01fb162d90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ca4a958e7514d19874e59da638f94c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6163464a857a49f686cdcd83acd4981d",
              "IPY_MODEL_9287dd4d02dc492bb01c4c9d3a0f21d8"
            ]
          }
        },
        "9ca4a958e7514d19874e59da638f94c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6163464a857a49f686cdcd83acd4981d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b05b8f32c5a34944b31d574229bcf384",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0f1be57477a4ef1a35339033bc90a9d"
          }
        },
        "9287dd4d02dc492bb01c4c9d3a0f21d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca708ad9900f4a709e1fcb853176f977",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:21&lt;00:00, 25.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98f06f73797e4c478ad96859ee841531"
          }
        },
        "b05b8f32c5a34944b31d574229bcf384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0f1be57477a4ef1a35339033bc90a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca708ad9900f4a709e1fcb853176f977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98f06f73797e4c478ad96859ee841531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parker-erickson/BERT-question-answering/blob/main/question_answering_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5XyK4DLEh2A"
      },
      "source": [
        "###### Parker Erickson\n",
        "###### Ryan Beck\n",
        "###### Cassandra Cabrera\n",
        "###### 12/18/2020\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdoJkfLkpxVz"
      },
      "source": [
        "# **Question Answering with BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKurgp5FETRx"
      },
      "source": [
        "## **Introduction**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqWJ2p9cp4VJ"
      },
      "source": [
        "___\n",
        "***BERT***\n",
        "\n",
        ">BERT stands for Bidirectional Encoder Representations from Transformers, and is designed to bidirectionally train representations of text, which is unlabeled, through analysis of all sides of a neural networks layer’s. Through the process of fine-tuning, Bert can create highly accurate models to solve many problems, without requiring architecture specific to each task. In the case of this project, it will be used to create a Question answering algorithm that takes in a question and responds with the best fit response.\n",
        "\n",
        ">Developed by google and introduced in the paper https://arxiv.org/pdf/1810.04805.pdf\n",
        "Bert is a response to similar work such as GPT-2, and ELMo. With a shift to the use of transformers from LSTM models, models such as BERT are increasing in popularity as they are faster and more accurate than previous implementations of LSTM models. The Model architecture of BERT is multi-layered, and the transformer utilizes bidirectional self-attention. This means that it creates connections between indices adjacent to the input, which is why it excels at language processing tasks. Language is, after all, an array of words that only have meaning when all of the adjacent words are the context of each other.\n",
        "___\n",
        "***DATASET***\n",
        "\n",
        ">For the dataset, the Stanford Question and Answer Dataset 2.0 is used (SQuAD 2.0) to train the BERT model. It contains more than 100,000 question and answer pairs, as well as over 50,000 questions which have no answer. This adds extra complexity as the algorithm must be written to identify when the question does and does not have a definite answer. \n",
        "\n",
        "_______________________________________________________\n",
        "BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n",
        "\n",
        "SQuAD 2.0: https://rajpurkar.github.io/SQuAD-explorer/\n",
        "________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHrf33GpsAEv"
      },
      "source": [
        "##**Setup**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsVWp4g-qMu5"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4En3P9vzsix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f6815a-7fd5-4e1f-da8e-9b35f080648b"
      },
      "source": [
        "!pip install transformers\n",
        "import requests\n",
        "import random\n",
        "import gc\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "\n",
        "max_len = 384\n",
        "configuration = BertConfig()  # default parameters and configuration for BERT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 33.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=ea7bfb1f98a61e30f43699235cd7dc280b330ee6e137f452bce02e924296babd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJVWNid4sG-4"
      },
      "source": [
        "###**Retrieve Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A_Akd17FcVO"
      },
      "source": [
        "The data was downloaded from the SQuAD website, and uploaded to Github. \n",
        "\n",
        "Initially there was an issue with the file size limit on Github, as the initial commit cannot be above 25MB but the overall limit is 100MB. With the Database File being over 40MB this initally posed a problem, but Cassandra was able to upload the data.\n",
        "\n",
        "The data uploads to the notebook quickly and contains titles of topics and questions that fall into those topics. The Questions can have multiple answers or be impossible to answer. As well, they also have a reference to the index at which they start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diwyaGTsz3VW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dcf789-a0c5-476d-d040-baf141131407"
      },
      "source": [
        "train_url = 'https://raw.githubusercontent.com/cass-cabrera/data/master/train-v2.0.json'\n",
        "dev_url = 'https://raw.githubusercontent.com/cass-cabrera/data/master/dev-v2.0.json'\n",
        "# r = requests.get(train_url).json()\n",
        "train_path = keras.utils.get_file(\"train.json\", train_url)\n",
        "eval_path = keras.utils.get_file(\"dev.json\", dev_url)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/cass-cabrera/data/master/train-v2.0.json\n",
            "42131456/42123633 [==============================] - 1s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/cass-cabrera/data/master/dev-v2.0.json\n",
            "4374528/4370528 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YMysiC1xbim"
      },
      "source": [
        "with open(train_path) as f:\n",
        "  raw_train_data = json.load(f)\n",
        "\n",
        "with open(eval_path) as f:\n",
        "  raw_eval_data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BejxJP9HsLNP"
      },
      "source": [
        "##**Set-up BERT tokenizer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z_GN0UXFbiX"
      },
      "source": [
        "When pre-training a BERT model, a WordPiece Tokenization is applied with a word masking rate of about 15% by default. This means that the text used for training is encoded as a high-dimension vector representation. \n",
        "\n",
        "The word masking is important for the bi-directional encoding the BERT algorithm utilizes. If it did not mask words in the training process, words would refer to themselves, and would then overfit the model. Thus, the random masking function allows for each token to build a comprehensive relationship to the left and right side of each sentence being trained on. \n",
        "\n",
        "This allows for a better predicted answer, as it comes to question answering.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peDk9EKxsLbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f70c3487ec1044069b32219480a253d0",
            "7cc62d1966464ddc80ab11b27f05fec6",
            "d476d3c168db4df9a9af22b47adcef51",
            "fd84b542a6644d78be436c8edb17c848",
            "6a8e282c9fe3495b8e78fb82b6cf7ebf",
            "ae4e315f5b634dcf9e3f0a5b62151155",
            "aa2f65437a194feab00a2e62defc9dbd",
            "8e17bdc16fb94f698e715a471b2c95a2"
          ]
        },
        "outputId": "31a2804a-a4f2-4a35-c7f2-0707089d798e"
      },
      "source": [
        "# Save the slow pretrained tokenizer\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "save_path = \"bert_base_uncased/\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "slow_tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# Load the fast tokenizer from saved file\n",
        "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f70c3487ec1044069b32219480a253d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_aH9Cpsciu"
      },
      "source": [
        "##**Preprocessing and Data Exploration**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR3ft4PdFbN-"
      },
      "source": [
        "In the preprocessing and data exploration step, the SQuAD 2.0 data is munged and tokenized to represent the indexes where the answers end for each question input. This is essential for the training process, as described earlier, because the character data is transposed into numerical vector representations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyCe1SITspLM"
      },
      "source": [
        "class SquadExample:\n",
        "  def __init__(self, question, context, start_char_idx, answer_text, all_answers, is_impossible):\n",
        "    self.question = question\n",
        "    self.context = context\n",
        "    self.start_char_idx = start_char_idx\n",
        "    self.answer_text = answer_text\n",
        "    self.all_answers = all_answers\n",
        "    self.is_impossible = is_impossible\n",
        "    self.skip = False\n",
        "\n",
        "  def preprocess(self):\n",
        "    context = self.context\n",
        "    question = self.question\n",
        "    answer_text = self.answer_text\n",
        "    start_char_idx = self.start_char_idx\n",
        "\n",
        "    # Clean context, answer and question\n",
        "    context = \" \".join(str(context).split())\n",
        "    question = \" \".join(str(question).split())\n",
        "    answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "    # Find end character index of answer in context\n",
        "    end_char_idx = start_char_idx + len(answer)\n",
        "    if end_char_idx >= len(context):\n",
        "      self.skip = True\n",
        "      return\n",
        "\n",
        "    # Mark the character indexes in context that are in answer\n",
        "    is_char_in_ans = [0] * len(context)\n",
        "    for idx in range(start_char_idx, end_char_idx):\n",
        "      is_char_in_ans[idx] = 1\n",
        "\n",
        "    # Tokenize context\n",
        "    tokenized_context = tokenizer.encode(context)\n",
        "\n",
        "    # Find tokens that were created from answer characters\n",
        "    ans_token_idx = []\n",
        "    for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "      if sum(is_char_in_ans[start:end]) > 0:\n",
        "        ans_token_idx.append(idx)\n",
        "\n",
        "    if len(ans_token_idx) == 0:\n",
        "      self.skip = True\n",
        "      return\n",
        "\n",
        "    # Find start and end token index for tokens from answer\n",
        "    start_token_idx = ans_token_idx[0]\n",
        "    end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "    # Tokenize question\n",
        "    tokenized_question = tokenizer.encode(question)\n",
        "\n",
        "    # Create inputs\n",
        "    input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "    token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
        "        tokenized_question.ids[1:]\n",
        "    )\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Pad and create attention masks.\n",
        "    # Skip if truncation is needed\n",
        "    padding_length = max_len - len(input_ids)\n",
        "    if padding_length > 0:  # pad\n",
        "      input_ids = input_ids + ([0] * padding_length)\n",
        "      attention_mask = attention_mask + ([0] * padding_length)\n",
        "      token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "    elif padding_length < 0:  # skip\n",
        "      self.skip = True\n",
        "      return\n",
        "\n",
        "    self.input_ids = input_ids\n",
        "    self.token_type_ids = token_type_ids\n",
        "    self.attention_mask = attention_mask\n",
        "    self.start_token_idx = start_token_idx\n",
        "    self.end_token_idx = end_token_idx\n",
        "    self.context_token_to_char = tokenized_context.offsets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRddl3oVuzv_"
      },
      "source": [
        "def create_squad_examples(raw_data):\n",
        "  global is_impossible\n",
        "  global plausible_answers\n",
        "  global no_answer\n",
        "  squad_examples = []\n",
        "  for item in raw_data[\"data\"]:\n",
        "    for para in item[\"paragraphs\"]:\n",
        "      context = para[\"context\"]\n",
        "      for qa in para[\"qas\"]:\n",
        "        question = qa[\"question\"]\n",
        "        if qa[\"is_impossible\"] == False:\n",
        "          answer_text = qa[\"answers\"][0][\"text\"]\n",
        "          all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "          start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "        elif \"plausible_answers\" in qa and len(qa['plausible_answers']) > 0:\n",
        "          answer_text = qa[\"plausible_answers\"][0][\"text\"]\n",
        "          all_answers = [_[\"text\"] for _ in qa[\"plausible_answers\"]]\n",
        "          start_char_idx = qa[\"plausible_answers\"][0][\"answer_start\"]\n",
        "          is_impossible += 1\n",
        "          plausible_answers += 1\n",
        "        else:\n",
        "          is_impossible +=1\n",
        "          no_answer +=1\n",
        "          continue\n",
        "        squad_eg = SquadExample(\n",
        "            question, context, start_char_idx, answer_text, all_answers, qa[\"is_impossible\"]\n",
        "        )\n",
        "        squad_eg.preprocess()\n",
        "        squad_examples.append(squad_eg)\n",
        "  return squad_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq_qcCjExSnO"
      },
      "source": [
        "def create_inputs_targets(squad_examples):\n",
        "  dataset_dict = {\n",
        "      \"input_ids\": [],\n",
        "      \"token_type_ids\": [],\n",
        "      \"attention_mask\": [],\n",
        "      \"start_token_idx\": [],\n",
        "      \"end_token_idx\": [],\n",
        "  }\n",
        "  for item in squad_examples:\n",
        "    if item.skip == False:\n",
        "      for key in dataset_dict:\n",
        "        dataset_dict[key].append(getattr(item, key))\n",
        "  for key in dataset_dict:\n",
        "    dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "  x = [\n",
        "      dataset_dict[\"input_ids\"],\n",
        "      dataset_dict[\"token_type_ids\"],\n",
        "      dataset_dict[\"attention_mask\"],\n",
        "  ]\n",
        "  y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyL0JDiqwPy8"
      },
      "source": [
        "Based on creating SQUAD examples from the raw data, we can see that we initially have around 130,000 training data records and 12,000 evaluation data records. We noticed that there were some questions in the dataset that had a boolean flag to tell us how many questions were considered impossible to answer. From that we then analyzed of those that were impossible to answer if there were  any that had a suggested plausible answer, or no answer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oujYqqW6wVDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b06b9ac-9ba9-4f74-8d83-b15a71fe3f39"
      },
      "source": [
        "is_impossible = 0\n",
        "plausible_answers = 0\n",
        "no_answer = 0\n",
        "\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "print(f\"{len(train_squad_examples)} training data records to begin with.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "print(f\"{len(eval_squad_examples)} evaluation data records to begin with.\")\n",
        "\n",
        "print(f\"{is_impossible} of questions are considered impossible to answer.\")\n",
        "print(f\"{plausible_answers} of the impossible questions are suggested to have a plausible answer.\")\n",
        "print(f\"{no_answer} of the impossible questions have no possible answer.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130319 training data records to begin with.\n",
            "11858 evaluation data records to begin with.\n",
            "49443 of questions are considered impossible to answer.\n",
            "49428 of the impossible questions are suggested to have a plausible answer.\n",
            "15 of the impossible questions have no possible answer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHsLsIK7wbat"
      },
      "source": [
        "Because of the very small amount of  questions with no possible answer we decided to remove these from our data set as well as any data records that exceed our max length of 364 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIPdVykhwdNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0bd2c7-957a-4885-c2ff-15de0a1494f0"
      },
      "source": [
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{np.array(x_train).shape[1]} training points created.\")\n",
        "\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{np.array(x_eval).shape[1]} evaluation points created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128178 training points created.\n",
            "11587 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GmbMZK-XLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ee1608-9fee-43f1-b607-793c5a4d8312"
      },
      "source": [
        "for x in random.sample(train_squad_examples, 3):\n",
        "  print(\"Question: \", x.question)\n",
        "  print(\"Context: \", x.context)\n",
        "  print(\"Starting Answer Index: \", x.start_char_idx)\n",
        "  print(\"Answer: \", x.answer_text)\n",
        "  print(\"All Possible Answers: \", x.all_answers)\n",
        "  print(\"Is Impossible: \", x.is_impossible, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:  In what year did the Dutch give New York back to the English?\n",
            "Context:  On August 24, 1673, Dutch captain Anthonio Colve took over the colony of New York from England and rechristened it \"New Orange\" to honor the Prince of Orange, King William III. However, facing defeat from the British and French, who had teamed up to destroy Dutch trading routes, the Dutch returned the island to England in 1674.\n",
            "Starting Answer Index:  324\n",
            "Answer:  1674\n",
            "All Possible Answers:  ['1674']\n",
            "Is Impossible:  False \n",
            "\n",
            "Question:  One rod in the second box from the right is what number?\n",
            "Context:  Mathematics: From the earliest the Chinese used a positional decimal system on counting boards in order to calculate. To express 10, a single rod is placed in the second box from the right. The spoken language uses a similar system to English: e.g. four thousand two hundred seven. No symbol was used for zero. By the 1st century BC, negative numbers and decimal fractions were in use and The Nine Chapters on the Mathematical Art included methods for extracting higher order roots by Horner's method and solving linear equations and by Pythagoras' theorem. Cubic equations were solved in the Tang dynasty and solutions of equations of order higher than 3 appeared in print in 1245 AD by Ch'in Chiu-shao. Pascal's triangle for binomial coefficients was described around 1100 by Jia Xian.\n",
            "Starting Answer Index:  129\n",
            "Answer:  10\n",
            "All Possible Answers:  ['10']\n",
            "Is Impossible:  False \n",
            "\n",
            "Question:  Central Asia linked Canada, the steppes to the north and whom?\n",
            "Context:  The Kushan Empire, a collection of Yuezhi tribes, took control of the region in the first century CE and ruled until the 4th century CE during which time Buddhism, Nestorian Christianity, Zoroastrianism, and Manichaeism were all practiced in the region. Later the Hephthalite Empire, a collection of nomadic tribes, moved into the region and Arabs brought Islam in the early eighth century. Central Asia continued in its role as a commercial crossroads, linking China, the steppes to the north, and the Islamic heartland.\n",
            "Starting Answer Index:  499\n",
            "Answer:  the Islamic heartland\n",
            "All Possible Answers:  ['the Islamic heartland']\n",
            "Is Impossible:  True \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlQqIiW8wgn8"
      },
      "source": [
        "##**Model Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb_4awwrT7Yn"
      },
      "source": [
        "The model is defined with three input layers, which are required for the TFBertModel class from the transformers library. This first model we will run will contain default parameters the most importantly being the BertConfig, which defines the attributes of the model itself. Some notable parameters of the config include the number of hidden layers and the dropout rate. The output of the Bert model is the start and end logits of the predicted text, which is then normalized to become probabilities of the answer text beginning at each index. Loss is calculated with SparseCategoricalCrossEntropy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YeA9GKQwynz"
      },
      "source": [
        "def create_model(bert_config=configuration):\n",
        "  ## BERT encoder\n",
        "  encoder = TFBertModel.from_pretrained(\"bert-base-uncased\", config=bert_config)\n",
        "\n",
        "  ## QA Model\n",
        "  input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "  token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "  attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "  embedding = encoder(\n",
        "    input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "  )[0]\n",
        "\n",
        "  start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "  start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "  end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "  end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "  start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "  end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "  model = keras.Model(\n",
        "    inputs=[input_ids, token_type_ids, attention_mask],\n",
        "    outputs=[start_probs, end_probs],\n",
        "  )\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "  optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "  model.compile(optimizer=optimizer, loss=[loss, loss], metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9cbcd2d188974b96bd9af01fb162d90e",
            "9ca4a958e7514d19874e59da638f94c1",
            "6163464a857a49f686cdcd83acd4981d",
            "9287dd4d02dc492bb01c4c9d3a0f21d8",
            "b05b8f32c5a34944b31d574229bcf384",
            "c0f1be57477a4ef1a35339033bc90a9d",
            "ca708ad9900f4a709e1fcb853176f977",
            "98f06f73797e4c478ad96859ee841531"
          ]
        },
        "id": "4s7RVB0f0mx0",
        "outputId": "3c275475-8ee1-4003-937f-9d57600defbf"
      },
      "source": [
        "K.clear_session()\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model = create_model()\n",
        "else:\n",
        "  model = create_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.19.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.19.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbcd2d188974b96bd9af01fb162d90e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f69e56895f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f69fced4e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f69e56895f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f69fced4e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f69e56895f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f69fced4e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f69fa8668c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f69fa8668c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f69fa8668c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,776\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R_-ePun08Ex"
      },
      "source": [
        "##**Evaluation Callback**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWg3Uuk9FaHp"
      },
      "source": [
        "This callback will be used at the end of every epoch in the model. The main purpose of this callback will be to test the model on the evaluation data at every epoch, as opposed to just at the end of training. That way we can see how it improves as the epochs continue. The evaluation data is tested in two ways. The first way is checking if the predicted text is an exact match of the target text. The second way is checking if the target text is a substring of the predicted text. We found many examples where the model would predict something like “in Normandy, France”, but the dataset would have the target value as just “France”.\n",
        "\n",
        "Aside from testing the evaluation data, the callback also returns some data in an output dataframe. This includes the normalized and decoded predicted and target values in each row, along with other related data. This dataframe can be used for diagnosing some issues as well as simply getting a visual look at the predicted values in plain text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEgCCfPb07cQ"
      },
      "source": [
        "def normalize_text(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  # Remove punctuations\n",
        "  exclude = set(string.punctuation)\n",
        "  text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "  # Remove articles\n",
        "  regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "  text = re.sub(regex, \" \", text)\n",
        "\n",
        "  # Remove extra white space\n",
        "  text = \" \".join(text.split())\n",
        "  return text\n",
        "\n",
        "\n",
        "class DiagnosticCallback(keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self, x_eval, y_eval, num_epochs):\n",
        "    self.x_eval = x_eval\n",
        "    self.y_eval = y_eval\n",
        "    self.num_epochs = num_epochs\n",
        "    self.q_and_a = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "    count = 0\n",
        "    count2 = 0\n",
        "    eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "    for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "      squad_eg = eval_examples_no_skip[idx]\n",
        "      offsets = squad_eg.context_token_to_char\n",
        "      start = np.argmax(start)\n",
        "      end = np.argmax(end)\n",
        "      if start >= len(offsets):\n",
        "        continue\n",
        "      pred_char_start = offsets[start][0]\n",
        "      if end < len(offsets):\n",
        "        pred_char_end = offsets[end][1]\n",
        "        pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "      else:\n",
        "        pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "      normalized_pred_ans = normalize_text(pred_ans)\n",
        "      normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
        "\n",
        "      if normalized_pred_ans in normalized_true_ans:\n",
        "        count += 1\n",
        "        exact = True\n",
        "      else:\n",
        "        exact = False\n",
        "\n",
        "      real_start = squad_eg.start_char_idx\n",
        "      if real_start >= pred_char_start and real_start < pred_char_end:\n",
        "        count2 += 1\n",
        "\n",
        "      if epoch + 1 == self.num_epochs:\n",
        "        self.q_and_a.append([squad_eg.question, normalized_pred_ans, normalized_true_ans, exact, squad_eg.is_impossible])\n",
        "\n",
        "\n",
        "    self.output = pd.DataFrame(self.q_and_a, columns=[\"question\", \"prediction\", \"target\", \"exact_match\", \"is_impossible\"])\n",
        "    acc = count / len(self.y_eval[0])\n",
        "    acc2 = count2 / len(self.y_eval[0])\n",
        "    print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n",
        "    print(f\"\\nepoch={epoch+1}, answer is a substring of context score={acc2:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYMGKKWr8NvO",
        "outputId": "1cd249ad-b112-480e-8ccb-49671500d0be"
      },
      "source": [
        "num_epochs = 3\n",
        "diagnostic_callback = DiagnosticCallback(x_eval, y_eval, num_epochs)\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=num_epochs, \n",
        "    verbose=2,\n",
        "    batch_size=32,\n",
        "    callbacks=[diagnostic_callback],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 542s - loss: 2.5477 - activation_loss: 1.3288 - activation_1_loss: 1.2189 - activation_acc: 0.6212 - activation_1_acc: 0.6621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch=1, exact match score=0.66\n",
            "\n",
            "epoch=1, answer is a substring of context score=0.72\n",
            "Epoch 2/3\n",
            "4006/4006 - 426s - loss: 1.6550 - activation_loss: 0.8733 - activation_1_loss: 0.7817 - activation_acc: 0.7282 - activation_1_acc: 0.7684\n",
            "\n",
            "epoch=2, exact match score=0.66\n",
            "\n",
            "epoch=2, answer is a substring of context score=0.72\n",
            "Epoch 3/3\n",
            "4006/4006 - 426s - loss: 1.2057 - activation_loss: 0.6403 - activation_1_loss: 0.5654 - activation_acc: 0.7908 - activation_1_acc: 0.8253\n",
            "\n",
            "epoch=3, exact match score=0.65\n",
            "\n",
            "epoch=3, answer is a substring of context score=0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGbtLw3oEFnp"
      },
      "source": [
        "We wanted to perform gridsearch on our TFBertModel, to find the best hyperparameters for its configuration parameter, BertConfig. We initally attempted to do this using scikit learn's GridSearchCV and found that due to the transformer type model we are using and the type of data we have, this wouldn't work. This lead us to looking into using HuggingFace's TFTrainer with Ray Tune, which is used when trying to fine-tune Transformers. But again, the format our data is in was not suitable to use TFTrainer. We finally decided to exhaustively search through our selected hyperparameters (num_hidden_layers, hidden_dropout_prob), while less efficient than a built in tool would have been for us, we were able to find that using 10 hidden layers and a hidden dropout probability of 0.1, we could achieve an accuracy of 82%, which was the best accuracy obtained throughout our manual cross checking of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RSXNmStL3Cm",
        "outputId": "70654ee7-3346-4411-8b06-8e6a7015354f"
      },
      "source": [
        "\n",
        "params = {'num_hidden_layers':[10,12,15,18], 'hidden_dropout_prob':[0.1,0.3,0.5]} #default hidden_layers=12, drouput = 0.1\n",
        "best_acc = 0\n",
        "best_acc_params = None\n",
        "for x in params['num_hidden_layers']:\n",
        "  for y in params['hidden_dropout_prob']:\n",
        "    K.clear_session()\n",
        "    config = BertConfig(num_hidden_layers=x, hidden_dropout_prob=y)\n",
        "    with strategy.scope():\n",
        "      model = create_model(config)\n",
        "    num_epochs = 3\n",
        "    diagnostic_callback = DiagnosticCallback(x_eval, y_eval, num_epochs)\n",
        "\n",
        "    history = model.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      epochs=num_epochs,\n",
        "      verbose=2,\n",
        "      batch_size=32,\n",
        "    )\n",
        "\n",
        "    curr_acc = max(history.history['activation_1_acc'])\n",
        "    if  curr_acc > best_acc:\n",
        "      best_acc = curr_acc\n",
        "      best_acc_params = (x, y)\n",
        "    gc.collect()\n",
        "    del model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1376d115f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f1383d31e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1376d115f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f1383d31e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f1376d115f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f1383d31e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f13816c58c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f13816c58c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f13816c58c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 473s - loss: 2.5652 - activation_loss: 1.3405 - activation_1_loss: 1.2248 - activation_acc: 0.6178 - activation_1_acc: 0.6582\n",
            "Epoch 2/3\n",
            "4006/4006 - 363s - loss: 1.6390 - activation_loss: 0.8663 - activation_1_loss: 0.7727 - activation_acc: 0.7318 - activation_1_acc: 0.7709\n",
            "Epoch 3/3\n",
            "4006/4006 - 364s - loss: 1.1620 - activation_loss: 0.6169 - activation_1_loss: 0.5451 - activation_acc: 0.7966 - activation_1_acc: 0.8296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 473s - loss: 3.0614 - activation_loss: 1.5955 - activation_1_loss: 1.4659 - activation_acc: 0.5570 - activation_1_acc: 0.5971\n",
            "Epoch 2/3\n",
            "4006/4006 - 365s - loss: 2.1836 - activation_loss: 1.1467 - activation_1_loss: 1.0369 - activation_acc: 0.6580 - activation_1_acc: 0.6989\n",
            "Epoch 3/3\n",
            "4006/4006 - 364s - loss: 1.8360 - activation_loss: 0.9678 - activation_1_loss: 0.8682 - activation_acc: 0.7004 - activation_1_acc: 0.7410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 474s - loss: 4.6505 - activation_loss: 2.4085 - activation_1_loss: 2.2421 - activation_acc: 0.3824 - activation_1_acc: 0.4174\n",
            "Epoch 2/3\n",
            "4006/4006 - 365s - loss: 3.1426 - activation_loss: 1.6462 - activation_1_loss: 1.4963 - activation_acc: 0.5399 - activation_1_acc: 0.5837\n",
            "Epoch 3/3\n",
            "4006/4006 - 367s - loss: 2.7620 - activation_loss: 1.4494 - activation_1_loss: 1.3126 - activation_acc: 0.5851 - activation_1_acc: 0.6269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 551s - loss: 2.5507 - activation_loss: 1.3324 - activation_1_loss: 1.2182 - activation_acc: 0.6199 - activation_1_acc: 0.6600\n",
            "Epoch 2/3\n",
            "4006/4006 - 431s - loss: 1.6576 - activation_loss: 0.8761 - activation_1_loss: 0.7815 - activation_acc: 0.7284 - activation_1_acc: 0.7683\n",
            "Epoch 3/3\n",
            "4006/4006 - 431s - loss: 1.2229 - activation_loss: 0.6511 - activation_1_loss: 0.5718 - activation_acc: 0.7882 - activation_1_acc: 0.8251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 553s - loss: 2.9733 - activation_loss: 1.5523 - activation_1_loss: 1.4211 - activation_acc: 0.5650 - activation_1_acc: 0.6095\n",
            "Epoch 2/3\n",
            "4006/4006 - 431s - loss: 2.1570 - activation_loss: 1.1329 - activation_1_loss: 1.0240 - activation_acc: 0.6611 - activation_1_acc: 0.7035\n",
            "Epoch 3/3\n",
            "4006/4006 - 430s - loss: 1.8241 - activation_loss: 0.9638 - activation_1_loss: 0.8603 - activation_acc: 0.7014 - activation_1_acc: 0.7439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 552s - loss: 4.5831 - activation_loss: 2.3664 - activation_1_loss: 2.2167 - activation_acc: 0.3912 - activation_1_acc: 0.4254\n",
            "Epoch 2/3\n",
            "4006/4006 - 430s - loss: 3.0859 - activation_loss: 1.6069 - activation_1_loss: 1.4790 - activation_acc: 0.5478 - activation_1_acc: 0.5907\n",
            "Epoch 3/3\n",
            "4006/4006 - 431s - loss: 2.7290 - activation_loss: 1.4252 - activation_1_loss: 1.3038 - activation_acc: 0.5911 - activation_1_acc: 0.6312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._12/attention/self/key/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 677s - loss: 2.5512 - activation_loss: 1.3339 - activation_1_loss: 1.2173 - activation_acc: 0.6201 - activation_1_acc: 0.6613\n",
            "Epoch 2/3\n",
            "4006/4006 - 529s - loss: 1.6662 - activation_loss: 0.8794 - activation_1_loss: 0.7868 - activation_acc: 0.7290 - activation_1_acc: 0.7677\n",
            "Epoch 3/3\n",
            "4006/4006 - 527s - loss: 1.2268 - activation_loss: 0.6500 - activation_1_loss: 0.5768 - activation_acc: 0.7888 - activation_1_acc: 0.8236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._12/attention/self/key/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 679s - loss: 3.0131 - activation_loss: 1.5670 - activation_1_loss: 1.4461 - activation_acc: 0.5621 - activation_1_acc: 0.6043\n",
            "Epoch 2/3\n",
            "4006/4006 - 528s - loss: 2.1916 - activation_loss: 1.1518 - activation_1_loss: 1.0398 - activation_acc: 0.6576 - activation_1_acc: 0.7003\n",
            "Epoch 3/3\n",
            "4006/4006 - 530s - loss: 1.8583 - activation_loss: 0.9795 - activation_1_loss: 0.8788 - activation_acc: 0.6988 - activation_1_acc: 0.7405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._12/attention/self/key/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 676s - loss: 4.5409 - activation_loss: 2.3439 - activation_1_loss: 2.1970 - activation_acc: 0.3944 - activation_1_acc: 0.4302\n",
            "Epoch 2/3\n",
            "4006/4006 - 528s - loss: 3.1329 - activation_loss: 1.6332 - activation_1_loss: 1.4998 - activation_acc: 0.5421 - activation_1_acc: 0.5853\n",
            "Epoch 3/3\n",
            "4006/4006 - 528s - loss: 2.7730 - activation_loss: 1.4488 - activation_1_loss: 1.3241 - activation_acc: 0.5862 - activation_1_acc: 0.6277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._17/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/output/dense/bias:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._17/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._15/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/value/bias:0', 'bert/encoder/layer_._17/attention/self/query/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/key/kernel:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._17/intermediate/dense/bias:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._16/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._16/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._15/intermediate/dense/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._17/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/query/kernel:0', 'bert/encoder/layer_._16/output/dense/bias:0', 'bert/encoder/layer_._17/intermediate/dense/kernel:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/output/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/query/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/key/kernel:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/self/query/kernel:0', 'bert/encoder/layer_._16/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._17/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._17/attention/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._15/attention/self/key/kernel:0', 'bert/encoder/layer_._16/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._15/intermediate/dense/bias:0', 'bert/encoder/layer_._17/output/dense/bias:0', 'bert/encoder/layer_._15/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/dense/bias:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/value/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 803s - loss: 2.5623 - activation_loss: 1.3390 - activation_1_loss: 1.2234 - activation_acc: 0.6191 - activation_1_acc: 0.6607\n",
            "Epoch 2/3\n",
            "4006/4006 - 627s - loss: 1.6798 - activation_loss: 0.8864 - activation_1_loss: 0.7934 - activation_acc: 0.7284 - activation_1_acc: 0.7668\n",
            "Epoch 3/3\n",
            "4006/4006 - 628s - loss: 1.2325 - activation_loss: 0.6537 - activation_1_loss: 0.5788 - activation_acc: 0.7884 - activation_1_acc: 0.8215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._17/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/output/dense/bias:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._17/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._15/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/value/bias:0', 'bert/encoder/layer_._17/attention/self/query/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/key/kernel:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._17/intermediate/dense/bias:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._16/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._16/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._15/intermediate/dense/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._17/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/query/kernel:0', 'bert/encoder/layer_._16/output/dense/bias:0', 'bert/encoder/layer_._17/intermediate/dense/kernel:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/output/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/query/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/key/kernel:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/self/query/kernel:0', 'bert/encoder/layer_._16/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._17/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._17/attention/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._15/attention/self/key/kernel:0', 'bert/encoder/layer_._16/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._15/intermediate/dense/bias:0', 'bert/encoder/layer_._17/output/dense/bias:0', 'bert/encoder/layer_._15/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/dense/bias:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/value/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 803s - loss: 3.0193 - activation_loss: 1.5728 - activation_1_loss: 1.4466 - activation_acc: 0.5612 - activation_1_acc: 0.6049\n",
            "Epoch 2/3\n",
            "4006/4006 - 627s - loss: 2.2379 - activation_loss: 1.1775 - activation_1_loss: 1.0604 - activation_acc: 0.6527 - activation_1_acc: 0.6963\n",
            "Epoch 3/3\n",
            "4006/4006 - 627s - loss: 1.8986 - activation_loss: 1.0003 - activation_1_loss: 0.8983 - activation_acc: 0.6944 - activation_1_acc: 0.7353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert/encoder/layer_._17/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/dense/bias:0', 'bert/encoder/layer_._12/attention/self/query/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/output/dense/bias:0', 'bert/encoder/layer_._12/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/dense/bias:0', 'bert/encoder/layer_._13/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/attention/output/dense/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/self/value/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/gamma:0', 'bert/encoder/layer_._13/attention/self/key/bias:0', 'bert/encoder/layer_._14/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/output/dense/kernel:0', 'bert/encoder/layer_._12/intermediate/dense/kernel:0', 'bert/encoder/layer_._13/intermediate/dense/bias:0', 'bert/encoder/layer_._13/attention/self/query/bias:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._17/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/attention/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/value/kernel:0', 'bert/encoder/layer_._13/output/dense/kernel:0', 'bert/encoder/layer_._14/intermediate/dense/bias:0', 'bert/encoder/layer_._14/intermediate/dense/kernel:0', 'bert/encoder/layer_._15/attention/self/query/bias:0', 'bert/encoder/layer_._12/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/kernel:0', 'bert/encoder/layer_._12/attention/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/value/bias:0', 'bert/encoder/layer_._17/attention/self/query/kernel:0', 'bert/encoder/layer_._16/intermediate/dense/kernel:0', 'bert/encoder/layer_._17/attention/self/key/kernel:0', 'bert/encoder/layer_._14/output/dense/kernel:0', 'bert/encoder/layer_._17/intermediate/dense/bias:0', 'bert/encoder/layer_._12/output/dense/kernel:0', 'bert/encoder/layer_._16/attention/self/value/kernel:0', 'bert/encoder/layer_._13/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/value/kernel:0', 'bert/encoder/layer_._17/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/value/kernel:0', 'bert/encoder/layer_._16/output/dense/kernel:0', 'bert/encoder/layer_._13/attention/self/query/kernel:0', 'bert/encoder/layer_._15/intermediate/dense/kernel:0', 'bert/encoder/layer_._14/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/attention/self/query/kernel:0', 'bert/encoder/layer_._17/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/query/kernel:0', 'bert/encoder/layer_._16/output/dense/bias:0', 'bert/encoder/layer_._17/intermediate/dense/kernel:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/intermediate/dense/bias:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/output/dense/bias:0', 'bert/encoder/layer_._14/attention/self/key/kernel:0', 'bert/encoder/layer_._12/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/query/bias:0', 'bert/encoder/layer_._13/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._16/attention/self/key/kernel:0', 'bert/encoder/layer_._14/attention/self/query/bias:0', 'bert/encoder/layer_._14/attention/self/value/bias:0', 'bert/encoder/layer_._12/output/dense/bias:0', 'bert/encoder/layer_._15/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._12/output/LayerNorm/gamma:0', 'bert/encoder/layer_._15/attention/self/query/kernel:0', 'bert/encoder/layer_._16/attention/self/key/bias:0', 'bert/encoder/layer_._12/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._14/attention/self/value/kernel:0', 'bert/encoder/layer_._17/output/dense/kernel:0', 'bert/encoder/layer_._17/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._17/attention/output/dense/kernel:0', 'bert/encoder/layer_._14/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._12/attention/self/query/bias:0', 'bert/encoder/layer_._15/attention/self/key/kernel:0', 'bert/encoder/layer_._16/attention/output/dense/kernel:0', 'bert/encoder/layer_._15/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._13/output/LayerNorm/beta:0', 'bert/encoder/layer_._14/output/dense/bias:0', 'bert/encoder/layer_._13/attention/self/key/kernel:0', 'bert/encoder/layer_._15/attention/output/dense/bias:0', 'bert/encoder/layer_._14/attention/output/dense/bias:0', 'bert/encoder/layer_._15/intermediate/dense/bias:0', 'bert/encoder/layer_._17/output/dense/bias:0', 'bert/encoder/layer_._15/attention/self/value/bias:0', 'bert/encoder/layer_._15/attention/self/key/bias:0', 'bert/encoder/layer_._17/attention/output/dense/bias:0', 'bert/encoder/layer_._16/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._16/attention/self/value/bias:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 804s - loss: 4.5108 - activation_loss: 2.3267 - activation_1_loss: 2.1841 - activation_acc: 0.3977 - activation_1_acc: 0.4366\n",
            "Epoch 2/3\n",
            "4006/4006 - 627s - loss: 3.1597 - activation_loss: 1.6443 - activation_1_loss: 1.5154 - activation_acc: 0.5401 - activation_1_acc: 0.5846\n",
            "Epoch 3/3\n",
            "4006/4006 - 628s - loss: 2.8050 - activation_loss: 1.4666 - activation_1_loss: 1.3384 - activation_acc: 0.5809 - activation_1_acc: 0.6257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUIslADLVe2V",
        "outputId": "67b21f24-7606-4ea2-ee12-ea2168685852"
      },
      "source": [
        "print(\"Best accuracy found: \", best_acc)\n",
        "print(\"Parameters for best accuracy: \", best_acc_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy found:  0.8296\n",
            "Parameters for best accuracy:  (10, 0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmN7zlQGeg86",
        "outputId": "c9066db5-bc4e-47c9-eb6a-f2c3557782ef"
      },
      "source": [
        "K.clear_session()\n",
        "config = BertConfig(num_hidden_layers=best_acc_params[0], hidden_dropout_prob=best_acc_params[1])\n",
        "with strategy.scope():\n",
        "  model = create_model(config)\n",
        "num_epochs = 3\n",
        "diagnostic_callback = DiagnosticCallback(x_eval, y_eval, num_epochs)\n",
        "\n",
        "history = model.fit(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  epochs=num_epochs, \n",
        "  verbose=2,\n",
        "  batch_size=32,\n",
        "  callbacks=[diagnostic_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4006/4006 - 468s - loss: 2.5742 - activation_loss: 1.3452 - activation_1_loss: 1.2290 - activation_acc: 0.6183 - activation_1_acc: 0.6578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch=1, exact match score=0.66\n",
            "\n",
            "epoch=1, answer is a substring of context score=0.73\n",
            "Epoch 2/3\n",
            "4006/4006 - 365s - loss: 1.6373 - activation_loss: 0.8638 - activation_1_loss: 0.7735 - activation_acc: 0.7331 - activation_1_acc: 0.7698\n",
            "\n",
            "epoch=2, exact match score=0.65\n",
            "\n",
            "epoch=2, answer is a substring of context score=0.74\n",
            "Epoch 3/3\n",
            "4006/4006 - 365s - loss: 1.1646 - activation_loss: 0.6173 - activation_1_loss: 0.5473 - activation_acc: 0.7980 - activation_1_acc: 0.8288\n",
            "\n",
            "epoch=3, exact match score=0.65\n",
            "\n",
            "epoch=3, answer is a substring of context score=0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBV5xZED3kA"
      },
      "source": [
        "We can see here that the accuracy is unfortunately not much higher than the orignial accuracy. However, we believe our model is preforming decently well on the SQuAD dataset. We've been able to reach up to 83% accuracy. The record for best accuracy on the Kaggle competition using this data is roughly 92%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T23tbgMIOJi"
      },
      "source": [
        "## Sample Output from the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "TEFT2WZ-B2PU",
        "outputId": "35356c82-3205-4a22-913f-54a16908ec46"
      },
      "source": [
        "output = diagnostic_callback.output\n",
        "output.sample(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>prediction</th>\n",
              "      <th>target</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8309</th>\n",
              "      <td>What was the source of the mistake?</td>\n",
              "      <td>icsi report</td>\n",
              "      <td>[wwf report, ipcc from wwf report, wwf report]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5318</th>\n",
              "      <td>What public entity of learning is often target...</td>\n",
              "      <td>governmental</td>\n",
              "      <td>[universities, private universities, private u...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10259</th>\n",
              "      <td>When was the Russian Policy \"Indigenization\" ...</td>\n",
              "      <td>1923</td>\n",
              "      <td>[1923]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2400</th>\n",
              "      <td>What did Lavoisier perceive the air had lost a...</td>\n",
              "      <td>weight</td>\n",
              "      <td>[weight, weight, weight, weight, weight]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10037</th>\n",
              "      <td>Friedrich Ratzel thought imperialism was what ...</td>\n",
              "      <td>necessary</td>\n",
              "      <td>[geographical societies in europe, necessary f...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8385</th>\n",
              "      <td>Who was the author of the fourth assessment re...</td>\n",
              "      <td>michael oppenheimer</td>\n",
              "      <td>[michael oppenheimer]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7529</th>\n",
              "      <td>What discouraged cultural exchange under the ...</td>\n",
              "      <td>mongols extensive west asian and european cont...</td>\n",
              "      <td>[mongols extensive west asian and european]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>What kind of education does Victoria have?</td>\n",
              "      <td>public universities</td>\n",
              "      <td>[diversified]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10657</th>\n",
              "      <td>What South Korean car manufacturer purchased t...</td>\n",
              "      <td>daewoo</td>\n",
              "      <td>[daewoo, daewoo, daewoo]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5038</th>\n",
              "      <td>What are responsibilities pharmacy technicians...</td>\n",
              "      <td>patients prescriptions and patient safety issues</td>\n",
              "      <td>[patients prescriptions and patient safety iss...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4301</th>\n",
              "      <td>How was Tymnet connected to dozens of other pr...</td>\n",
              "      <td>via x25x75 gateways</td>\n",
              "      <td>[via x25x75 gateways]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>What was the UK's least popular TV service in ...</td>\n",
              "      <td>freeview</td>\n",
              "      <td>[sky uk limited]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>Along with toys, where are oscillating cylinde...</td>\n",
              "      <td>ships</td>\n",
              "      <td>[models, models, models]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>What expression is generally used to convey up...</td>\n",
              "      <td>big o notation</td>\n",
              "      <td>[big o notation, big o notation, big o notation]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>How many tree species are in the rainforest?</td>\n",
              "      <td>1100</td>\n",
              "      <td>[1100, more than 1100, more than 1100, 1100]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3768</th>\n",
              "      <td>What do all other animal phyla lack?</td>\n",
              "      <td>true hox genes</td>\n",
              "      <td>[any true hox genes]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>How many Huguenots settled in Bedfordshire?</td>\n",
              "      <td>some</td>\n",
              "      <td>[twentyfive]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9962</th>\n",
              "      <td>What department in the U.S. spearheaded the ef...</td>\n",
              "      <td>state department</td>\n",
              "      <td>[state]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8884</th>\n",
              "      <td>What decreased the rate of flow and caused the...</td>\n",
              "      <td>rhine straightening program</td>\n",
              "      <td>[rhine straightening program]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>In what time period were lagerstatten first fo...</td>\n",
              "      <td>early cambrian</td>\n",
              "      <td>[early cambrian about 515 million years ago]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  ... is_impossible\n",
              "8309                 What was the source of the mistake?  ...         False\n",
              "5318   What public entity of learning is often target...  ...         False\n",
              "10259   When was the Russian Policy \"Indigenization\" ...  ...          True\n",
              "2400   What did Lavoisier perceive the air had lost a...  ...         False\n",
              "10037  Friedrich Ratzel thought imperialism was what ...  ...         False\n",
              "8385   Who was the author of the fourth assessment re...  ...          True\n",
              "7529    What discouraged cultural exchange under the ...  ...          True\n",
              "1140          What kind of education does Victoria have?  ...          True\n",
              "10657  What South Korean car manufacturer purchased t...  ...         False\n",
              "5038   What are responsibilities pharmacy technicians...  ...          True\n",
              "4301   How was Tymnet connected to dozens of other pr...  ...          True\n",
              "1011   What was the UK's least popular TV service in ...  ...          True\n",
              "1960   Along with toys, where are oscillating cylinde...  ...         False\n",
              "387    What expression is generally used to convey up...  ...         False\n",
              "3357        How many tree species are in the rainforest?  ...         False\n",
              "3768                What do all other animal phyla lack?  ...          True\n",
              "1609         How many Huguenots settled in Bedfordshire?  ...          True\n",
              "9962   What department in the U.S. spearheaded the ef...  ...          True\n",
              "8884   What decreased the rate of flow and caused the...  ...          True\n",
              "3545   In what time period were lagerstatten first fo...  ...          True\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCZ7NTjEc9h"
      },
      "source": [
        "##**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55e0ADXCFXd1"
      },
      "source": [
        "\n",
        "In the end, BERT proved itself to be a workhorse of a pre-trained model. It’s ability to be able to accomplish the task of question answering with high accuracy, as well as the prospect of being able to accomplish such tasks as a language inference and text generation, all at first glance seem to be problems which a computer would require significant power, let alone be unable to perform. However, this notebook shows that Google's BERT is able to train an accurate model on a modest computer or cloud processor, reaching an accuracy of almost 80% and an even higher ‘close-enough score’ of almost 80%. The accuracy would be higher without the addition of the ‘impossible’ answers, but those are important for the goal of this project, because they help bridge the gap between an AI and a program.\n",
        "\n",
        "Overall, with fine-tuning, BERT’s ability to generate answers to questions asked to it is impressive. However, there is room for improvement, and this paper did not reach the level of accuracy some others have been able to reach on Kaggle of about 92% with BERT for Question Answering. The implementation of analysis to select the most efficient number of hidden layers did increase our accuracy beyond the baseline. The Data we chose to use is not as widely used as the SQuAD1.1 and posed some challenges when it came to pre-processing and restructuring the data, but at the end it led to a deep learning model that is one step closer to the cutting edge, than if this just used the tried and tested SQuAD1.1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqcn2rVfFJil"
      },
      "source": [
        "##**Sources**\n",
        "\n",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
        "\n",
        "https://keras.io/examples/nlp/text_extraction_with_bert/\n",
        "\n",
        "https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRg_IFGlq7qc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}